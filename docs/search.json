[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Statistics and software resources",
    "section": "",
    "text": "R is a very powerful statistical software with a huge (very helpful!) online community. Because of this, there are lots of free resources to learn R so that you can apply the methods shown in this module.\nHere are a list of free resources that are available when getting to grips with R:\n\nR for data science: comprehensive introduction to R for data analysis, including worked examples and exercises for more practice\nR for the rest of us: A stats-free introduction to R coding (they also have tons of useful tips posted on their blog)\nIntroduction to R with Tidyverse: materials from a short course I teach going from absolute beginner to summarising, visualising and reporting data\nRegressions with R: materials from my Regressions with R short course with worked examples of linear and poisson regression\n\n\n\nSome Datacamp courses covering R and statistics:\n\nIntroduction to Statistics with R\nIntroduction to regressions in R\nHypothesis testing in R\nGLMs in R\nIntermediate regression in R\nHierarchical and mixed models in R: Where observations are not independent\nGAMs in R: For modelling nonlinear relationships"
  },
  {
    "objectID": "resources.html#statistics-with-r",
    "href": "resources.html#statistics-with-r",
    "title": "Statistics and software resources",
    "section": "",
    "text": "R is a very powerful statistical software with a huge (very helpful!) online community. Because of this, there are lots of free resources to learn R so that you can apply the methods shown in this module.\nHere are a list of free resources that are available when getting to grips with R:\n\nR for data science: comprehensive introduction to R for data analysis, including worked examples and exercises for more practice\nR for the rest of us: A stats-free introduction to R coding (they also have tons of useful tips posted on their blog)\nIntroduction to R with Tidyverse: materials from a short course I teach going from absolute beginner to summarising, visualising and reporting data\nRegressions with R: materials from my Regressions with R short course with worked examples of linear and poisson regression\n\n\n\nSome Datacamp courses covering R and statistics:\n\nIntroduction to Statistics with R\nIntroduction to regressions in R\nHypothesis testing in R\nGLMs in R\nIntermediate regression in R\nHierarchical and mixed models in R: Where observations are not independent\nGAMs in R: For modelling nonlinear relationships"
  },
  {
    "objectID": "resources.html#statistics-with-python",
    "href": "resources.html#statistics-with-python",
    "title": "Statistics and software resources",
    "section": "Statistics with Python",
    "text": "Statistics with Python\nPython is fast becoming one of the most popular coding language and a go-to for data science. Python tends to be used more for machine learning than statistics, but can do everything we covered in the module. It is also a freely available software and has a growing number of free resources available to help learn.\n\nPython for Data Analysis: Comprehensive ebook introducing the python language\nPython for data science: Python’s answer to R4DS, introduction to coding in python\n\n\nDatacamp courses\n\nIntroduction to statistics with python\nExploratory data analysis with python\nIntroduction to data science with python\nHypothesis testing in python\nIntroduction to regression with python\nIntroduction to linear models with python\nGLMs with python"
  },
  {
    "objectID": "part-2-slides.html#quantifying-differences-and-trends",
    "href": "part-2-slides.html#quantifying-differences-and-trends",
    "title": "Introduction to Statistics",
    "section": "Quantifying differences and trends",
    "text": "Quantifying differences and trends\nMost appropriate choice depends on intention, type of outcome, nature of the relationship\n\nComparison of variable between groups\nInvestigating trends over time\nRelationship between numeric variables\n\n\nOften, our research question will involve a comparison between groups, investigating trends over time, or investigating a relationship between two numeric variables. There are multiple approaches we can use to compare groups but the correct choice will depend on the outcome of interest and the type of relationship we are interested in. This section will describe the most common comparative statistics, their interpretations, and the reasons we may choose to use one approach over another."
  },
  {
    "objectID": "part-2-slides.html#comparing-categorical-outcomes",
    "href": "part-2-slides.html#comparing-categorical-outcomes",
    "title": "Introduction to Statistics",
    "section": "Comparing categorical outcomes",
    "text": "Comparing categorical outcomes\nCompare summary statistics (proportions, percentages, or rates) between groups\nAbsolute difference: Subtract values\nRelative difference: Divide values\n\nWhen comparing a categorical variable between groups, we are often comparing the summary measures that were introduced in the previous section: proportions, percentages, and rates. These summaries are either compared using the absolute difference or the relative difference."
  },
  {
    "objectID": "part-2-slides.html#comparing-categorical-outcomes-1",
    "href": "part-2-slides.html#comparing-categorical-outcomes-1",
    "title": "Introduction to Statistics",
    "section": "Comparing categorical outcomes",
    "text": "Comparing categorical outcomes\n\n\n\n\n\nSpecies\nTotal\nFemale penguins\nMale penguins\n\n\n\n\nAdelie\n146\n73 (50%)\n73 (50%)\n\n\nGentoo\n119\n58 (48.74%)\n61 (51.26%)\n\n\n\n\n\nAbsolute difference: 50% - 48.74% = 1.26%\nThe absolute difference between Adelie and Gentoo penguins is 1.26 percentage points."
  },
  {
    "objectID": "part-2-slides.html#comparing-categorical-outcomes-2",
    "href": "part-2-slides.html#comparing-categorical-outcomes-2",
    "title": "Introduction to Statistics",
    "section": "Comparing categorical outcomes",
    "text": "Comparing categorical outcomes\n\n\n\n\n\nSpecies\nTotal\nFemale penguins\nMale penguins\n\n\n\n\nAdelie\n146\n73 (50%)\n73 (50%)\n\n\nGentoo\n119\n58 (48.74%)\n61 (51.26%)\n\n\n\n\n\nRelative difference: 50% \\(\\div\\) 48.74% = 1.03\nThere were 1.03 times more female penguins in the Adelie group than the Gentoo penguin group\nNo difference would = 1"
  },
  {
    "objectID": "part-2-slides.html#comparing-categorical-outcomes-3",
    "href": "part-2-slides.html#comparing-categorical-outcomes-3",
    "title": "Introduction to Statistics",
    "section": "Comparing categorical outcomes",
    "text": "Comparing categorical outcomes\n\n\n\n\n\nSpecies\nTotal\nFemale penguins\nMale penguins\n\n\n\n\nAdelie\n146\n73 (50%)\n73 (50%)\n\n\nGentoo\n119\n58 (48.74%)\n61 (51.26%)\n\n\n\n\n\nRelative difference: 48.74% \\(\\div\\) 50% = 0.97\nThere were 0.97 times the percentage of female penguins in the Gentoo group than the Adelie penguin group\nLess than 1: a reduction"
  },
  {
    "objectID": "part-2-slides.html#comparing-numeric-outcomes",
    "href": "part-2-slides.html#comparing-numeric-outcomes",
    "title": "Introduction to Statistics",
    "section": "Comparing numeric outcomes",
    "text": "Comparing numeric outcomes\nCompare measures of centre/average (mean or median) between groups\nMost appropriate depends on distribution of sample in each group\nRequires a histogram per group\n\nThe most appropriate method to compare a numeric variable between groups will once again depend on the distribution of the variable. A comparison can either be made using the difference in means, where both groups have a normally distributed sample, or difference in medians, where the samples are skewed."
  },
  {
    "objectID": "part-2-slides.html#comparing-numeric-outcomes-1",
    "href": "part-2-slides.html#comparing-numeric-outcomes-1",
    "title": "Introduction to Statistics",
    "section": "Comparing numeric outcomes",
    "text": "Comparing numeric outcomes"
  },
  {
    "objectID": "part-2-slides.html#comparing-numeric-outcomes-2",
    "href": "part-2-slides.html#comparing-numeric-outcomes-2",
    "title": "Introduction to Statistics",
    "section": "Comparing numeric outcomes",
    "text": "Comparing numeric outcomes\nNeither the female nor the male group have a normal distribution → compare medians.\nMedian body mass of female penguins: 3650g\nMedian body mass of male penguins: 4300g\nAverage difference in body mass: -650g\nFemale penguins were 650g lighter on average compared to male penguins in this sample"
  },
  {
    "objectID": "part-2-slides.html#comparing-variables-over-time",
    "href": "part-2-slides.html#comparing-variables-over-time",
    "title": "Introduction to Statistics",
    "section": "Comparing variables over time",
    "text": "Comparing variables over time\nVisualised using line graph\nCommon comparisons: absolute difference, relative difference, or percentage change\nChoice depends on intention, interpretation differs\n\nWhen dealing with temporal data, it is important to quantify differences across time as well as visualising them using a line graph. Comparison across time is typically given as an absolute difference between time points, as a relative difference, or this is commonly converted into a percentage change."
  },
  {
    "objectID": "part-2-slides.html#section-2",
    "href": "part-2-slides.html#section-2",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "Recall the line graph given in an earlier section showing the reduction in the number of violent crimes recorded between 2010 and 2020: This difference can be quantified by comparing the number of violent crimes recorded in 2010 and 2020."
  },
  {
    "objectID": "part-2-slides.html#section-3",
    "href": "part-2-slides.html#section-3",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "Recall the line graph given in an earlier section showing the reduction in the number of violent crimes recorded between 2010 and 2020: This difference can be quantified by comparing the number of violent crimes recorded in 2010 (1,841,000 and 2020 1,239,000.)"
  },
  {
    "objectID": "part-2-slides.html#comparing-variables-over-time-1",
    "href": "part-2-slides.html#comparing-variables-over-time-1",
    "title": "Introduction to Statistics",
    "section": "Comparing variables over time",
    "text": "Comparing variables over time\nAbsolute difference: 1,841,000 - 1,239,000 = 602,000\nThere were 602,000 less violent crimes reported in 2020 compared to 2010\nRelative difference: 1,841,000 ÷ 1,239,000 = 1.486\nThere were 1.486 times more violent crimes reported in 2010 compared to 2020\n\nThe absolute difference is found by subtracting the number of violent crimes recorded in 2020, 1,239,000, by the number in 2010, 1,841,000. There were 602,000 ;ess violent crimes reported in 2020 compared to 2010.\nThe relative difference is found by dividing one count by the other. In this example, the relative difference (1,841,000 / 1,239,000) is 1.486. This means that there were 1.486 times more violent crimes reported in 2020 compared to 2010."
  },
  {
    "objectID": "part-2-slides.html#comparing-variables-over-time-2",
    "href": "part-2-slides.html#comparing-variables-over-time-2",
    "title": "Introduction to Statistics",
    "section": "Comparing variables over time",
    "text": "Comparing variables over time\nThe percentage change can also be found by converting the relative difference\nCompare relative difference to no difference: 1.486 - 1 = 0.486\nConvert the proportion change to percentage: 0.486 x 100%\n= 48.6%\nThere were 48.6% more violent crimes reported in 2010 than 2020\n\nThe percentage change can be found by comparing the relative difference to the null value of 1 (no relative difference). When comparing 2010 to 2020, the relative difference was 0.486 above 1, giving the proportion increase. This can be multiplied by 100 to give a percentage increase of 48.6%. Therefore, there were 48.6% more violent crimes reported in 2010 compared to 2020."
  },
  {
    "objectID": "part-2-slides.html#comparing-variables-over-time-3",
    "href": "part-2-slides.html#comparing-variables-over-time-3",
    "title": "Introduction to Statistics",
    "section": "Comparing variables over time",
    "text": "Comparing variables over time\nPercentage reduction found in similar way\nRelative difference: 1,239,000 ÷ 1,841,000 = 0.673\nCompare to no difference: 1 - 0.673 = 0.327 (32.7%)\nThere were 32.7% fewer violent crimes reported in 2020 than 2010\n\nThe relative difference can also be found by comparing 2020 to 2010 if we want to give the relative or percentage decrease in violent crime. The relative difference (1,239,000 / 1,841,000) is 0.673, so there were 0.673 times the number of crimes reported in 2020 than 2010. This result is not intuitive, so converting the difference into a percentage decrease can make the value easier to interpret. As with an increase, we first find the difference between the relative difference and the null (1 - 0.673). This gives a proportion decrease of 0.327 or a percentage decrease of 32.7%. Therefore, there were 32.7% fewer violent crimes reported in 2020 compared to 2010."
  },
  {
    "objectID": "part-2-slides.html#relationship-between-numeric-variables",
    "href": "part-2-slides.html#relationship-between-numeric-variables",
    "title": "Introduction to Statistics",
    "section": "Relationship between numeric variables",
    "text": "Relationship between numeric variables\nScatterplot used to visualise trends\nStrength of relationship quantified using correlation coefficients\nChoice of coefficients depends on if trend is linear or not\n\nLinear trend: Pearson’s correlation coefficient\nNonlinear trend: Spearman’s correlation coefficient\n\n\nCorrelation coefficients are summary statistics that describe the strength and direction of a relationship between two numeric variables. There are different types of correlation coefficients that exist, the choice of which depends on the nature of the trend it is measuring: is it linear or nonlinear?\nThe Pearson’s correlation coefficient measures the association between numeric variables if we assume it is linear. It essentially measures how close points lie to the line of best fit added to a scatterplot. The alternative to Pearson’s correlation is Spearman’s correlation coefficient, this measures the general trend upwards or downwards, whether or not this is linear. As with medians and IQRs, Spearman’s correlation coefficient uses less of the data than Pearson’s so we only use it where necessary."
  },
  {
    "objectID": "part-2-slides.html#correlation-coefficients",
    "href": "part-2-slides.html#correlation-coefficients",
    "title": "Introduction to Statistics",
    "section": "Correlation coefficients",
    "text": "Correlation coefficients\nTake value between -1 and 1\nCorrelation of 0 means no association\nCloser coefficient is to +1/-1, the stronger the positive/negative association is\n\nCorrelation coefficients take a value between -1 and 1. A value of 0 represents no association, values of +/- 1 represent perfect association (a straight or curved line depending on the choice of statistic). Generally, a correlation coefficient will lie between 0 and +/- 1 where the further the value gets from 0, the stronger the relationship is."
  },
  {
    "objectID": "part-2-slides.html#section-4",
    "href": "part-2-slides.html#section-4",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "A correlation coefficient is said to show a positive association if the value is above 0. This means as one variable increases, the other also tends to increase:"
  },
  {
    "objectID": "part-2-slides.html#what-are-inferential-statistics",
    "href": "part-2-slides.html#what-are-inferential-statistics",
    "title": "Introduction to Statistics",
    "section": "What are inferential statistics?",
    "text": "What are inferential statistics?\n\n\n\n\n\n\nAt the beginning of the course, we saw that one of the main aims of statistics is to make inferences about a target population of interest based on results of analysis applied to a random sample. These inferences require inferential statistics,"
  },
  {
    "objectID": "part-2-slides.html#what-are-inferential-statistics-1",
    "href": "part-2-slides.html#what-are-inferential-statistics-1",
    "title": "Introduction to Statistics",
    "section": "What are inferential statistics?",
    "text": "What are inferential statistics?\nInferential statistics make inferences about target population based on a random, representative sample.\nCombine sample estimates with sample size and level of precision\nMost common inferential statistics: p-values and confidence intervals\n\nThese are estimated by combining results from the random, representative sample taken from the target population, and information about the sample size and precision of the sample estimate."
  },
  {
    "objectID": "part-2-slides.html#measures-of-precision",
    "href": "part-2-slides.html#measures-of-precision",
    "title": "Introduction to Statistics",
    "section": "Measures of precision",
    "text": "Measures of precision\nPrecision of an estimate quantified by standard error (SE)\nBased on sample size and sample variability\nDifferent formula for each type of estimate (e.g. mean, percentage, difference between means)\n\n\\(SE(\\bar{x}) = \\frac{SD}{\\sqrt{n}}\\)\n\n\nInferential statistics require a measure of how precise a sample estimate is. Precision is quanti􀏐ied using the standard error (SE), calculated using the sample size and sample variability. The formula used to calculate a standard error depends on the type of parameter we wish to obtain from the target. For example, the standard error of a single mean (𝑆𝐸(𝑥)̄ ) is found by dividing the sample standard deviation (𝑆𝐷) by the square root of the sample size (𝑛):"
  },
  {
    "objectID": "part-2-slides.html#measures-of-precision-1",
    "href": "part-2-slides.html#measures-of-precision-1",
    "title": "Introduction to Statistics",
    "section": "Measures of precision",
    "text": "Measures of precision\n\n\nLarger SE → less precise\n\nSmaller SE → more precise\n\n\n\n\\(SE(\\bar{x}) = \\frac{SD}{\\sqrt{n}}\\)\n\n\nFor every parameter of interest:\n\nLarger sample, higher precision → lower standard error\nMore variability, lower precision → higher standard error\n\nInferential statistics work based on the central limit theorem\n\n\nRegardless of the formula used or the parameter of interest, the larger a sample is, the more precise an estimate will be. Conversely, the more varied a sample is, the less precise an estimate is. A precise estimate is represented by a small standard error value. Standard errors are used to estimate inferential statistics (p‑values and con􀏐idence intervals) based on the central limit theorem."
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem",
    "href": "part-2-slides.html#central-limit-theorem",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-1",
    "href": "part-2-slides.html#central-limit-theorem-1",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-2",
    "href": "part-2-slides.html#central-limit-theorem-2",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-3",
    "href": "part-2-slides.html#central-limit-theorem-3",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-4",
    "href": "part-2-slides.html#central-limit-theorem-4",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-5",
    "href": "part-2-slides.html#central-limit-theorem-5",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-6",
    "href": "part-2-slides.html#central-limit-theorem-6",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-7",
    "href": "part-2-slides.html#central-limit-theorem-7",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-8",
    "href": "part-2-slides.html#central-limit-theorem-8",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-9",
    "href": "part-2-slides.html#central-limit-theorem-9",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-10",
    "href": "part-2-slides.html#central-limit-theorem-10",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-11",
    "href": "part-2-slides.html#central-limit-theorem-11",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-12",
    "href": "part-2-slides.html#central-limit-theorem-12",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-13",
    "href": "part-2-slides.html#central-limit-theorem-13",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-14",
    "href": "part-2-slides.html#central-limit-theorem-14",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#central-limit-theorem-15",
    "href": "part-2-slides.html#central-limit-theorem-15",
    "title": "Introduction to Statistics",
    "section": "Central limit theorem",
    "text": "Central limit theorem"
  },
  {
    "objectID": "part-2-slides.html#confidence-intervals",
    "href": "part-2-slides.html#confidence-intervals",
    "title": "Introduction to Statistics",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nA range of values the true population parameter is compatible with\nBased on sample estimate, precision, and confidence level\n\n\nA con􀏐idence interval is a range of values that the true population statistic is compatible with based on the sample estimate, precision, and some pre‑de􀏐ined level of con􀏐idence. The con􀏐idence level can be adjusted depending on how con􀏐ident we wish to be about the true population parameter."
  },
  {
    "objectID": "part-2-slides.html#section-11",
    "href": "part-2-slides.html#section-11",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "Confidence levels\nNumber of SEs\n\n\n\n\n80%\n1.282\n\n\n90%\n1.645\n\n\n95%\n1.960\n\n\n99%\n2.576\n\n\n99.9%\n3.291"
  },
  {
    "objectID": "part-2-slides.html#confidence-intervals-1",
    "href": "part-2-slides.html#confidence-intervals-1",
    "title": "Introduction to Statistics",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nA range of values the true population parameter is compatible with\nBased on sample estimate, precision, and confidence level\n\n\n\nBased on central limit theorem, can capture ranges we would expect a percentage of parameter estimates to lie:\n\n\n\n\\(\\bar{x} \\pm 1.96 \\times SE(\\bar{x})\\)\n\n\nThe con􀏐idence interval is created assuming the central limit theorem. As the hypothetical repeated estimates are assumed to follow a normal distribution, we can use the sample estimate of the parameter and the standard error to obtain ranges within which we would expect a certain percentage of parameter estimates to lie."
  },
  {
    "objectID": "part-2-slides.html#confidence-interval-example",
    "href": "part-2-slides.html#confidence-interval-example",
    "title": "Introduction to Statistics",
    "section": "Confidence interval example",
    "text": "Confidence interval example\nLet’s compare the body mass of our penguins between sexes.\n\nFirst, we want to check the distribution of these samples:"
  },
  {
    "objectID": "part-2-slides.html#confidence-interval-example-1",
    "href": "part-2-slides.html#confidence-interval-example-1",
    "title": "Introduction to Statistics",
    "section": "Confidence interval example",
    "text": "Confidence interval example\nBoth groups appear to be normally distributed, so we can compare the means.\nMean body mass of male penguins: 4010.28g\nMean body mass of female penguins: 3419.16g\nDifference in the means (of the sample): 4010.28g - 3419.16g\n= 591.12g"
  },
  {
    "objectID": "part-2-slides.html#confidence-interval-example-2",
    "href": "part-2-slides.html#confidence-interval-example-2",
    "title": "Introduction to Statistics",
    "section": "Confidence interval example",
    "text": "Confidence interval example\nDifference in the means (of the sample): 591.12g\nStandard error of the mean difference= 4.23g\n95% confidence interval: 591.12 \\(\\pm\\) 1.96 \\(\\times\\) 4.23\n= 582.83g, 599.42g\nBut what does that mean??"
  },
  {
    "objectID": "part-2-slides.html#confidence-interval-example-3",
    "href": "part-2-slides.html#confidence-interval-example-3",
    "title": "Introduction to Statistics",
    "section": "Confidence interval example",
    "text": "Confidence interval example\n95% confidence interval: 582.83g, 599.42g\nWe are 95% confident that male penguins were between 582.83g and 599.42g heavier than female penguins on average.\nNote that this confidence interval only contains positive values."
  },
  {
    "objectID": "part-2-slides.html#p-values",
    "href": "part-2-slides.html#p-values",
    "title": "Introduction to Statistics",
    "section": "p-values",
    "text": "p-values\n\nProbability of obtaining a result as extreme or more extreme as the sample if the null hypothesis is true\nNull hypothesis (H0): no difference/association\n\n\nAnother commonly used inferential statistic is the p‑value. A p‑value is the probability of obtaining a sample estimate as extreme, or more extreme, than the current if some null hypothesis (H0) were true. The null hypothesis is usually ‘no difference’ or ‘no association’, depending on the value being tested."
  },
  {
    "objectID": "part-2-slides.html#p-values-1",
    "href": "part-2-slides.html#p-values-1",
    "title": "Introduction to Statistics",
    "section": "p-values",
    "text": "p-values\n\n\nIf we consider the normal distribution of repeated sample estimates, the p‑value is estimated by assuming the null hypothesis is true (and is therefore the peak of the distribution) and measuring how far the sample value is from this relative to the spread of the distribution (the standard error). The closer the sample estimate is to the null hypothesis, the more likely it was to occur if the null hypothesis were true, and the higher the p‑value"
  },
  {
    "objectID": "part-2-slides.html#p-values-2",
    "href": "part-2-slides.html#p-values-2",
    "title": "Introduction to Statistics",
    "section": "p-values",
    "text": "p-values\n\n\nThe further away from the null hypothesis, the less likely it would be to occur and the lower the p‑value."
  },
  {
    "objectID": "part-2-slides.html#p-values-3",
    "href": "part-2-slides.html#p-values-3",
    "title": "Introduction to Statistics",
    "section": "p-values",
    "text": "p-values\n\n\nProbability of obtaining a result as extreme or more extreme as the sample if the null hypothesis is true\nNull hypothesis (H0): no difference/association\n\n\n\n\nLow p-value: less evidence to support the null hypothesis\n\nVery low p-value is known as statistically significant"
  },
  {
    "objectID": "part-2-slides.html#statistical-significance",
    "href": "part-2-slides.html#statistical-significance",
    "title": "Introduction to Statistics",
    "section": "Statistical significance",
    "text": "Statistical significance\nOften significance is defined by arbitrary cut-off (usually 0.05)\nBe careful with these arbitrary definitions, it is not how probability behaves!\np &lt; 0.05 is significant at the 5% level\nWe never accept or reject a null hypothesis\n\nResults are often referred to as statistically signi􀏐icant if a p‑value falls below a certain threshold. This threshold is often set to 0.05, or a 5% chance that an estimate as extreme as the one obtained would occur if the null hypothesis were true. Although arbitrary cut‑offs may be useful in some situations, for example where a decision needs to be taken based on the results, this is not how probability behaves. In reality, there is very little difference between a p‑value of 0.049 (4.9% chance) and 0.051 (a 5.1% chance). Therefore, it is not advised to report ‘accepting’ or ‘rejecting’ a null hypothesis, despite how commonplace this is in some literature."
  },
  {
    "objectID": "part-2-slides.html#p-values-example",
    "href": "part-2-slides.html#p-values-example",
    "title": "Introduction to Statistics",
    "section": "p-values example",
    "text": "p-values example"
  },
  {
    "objectID": "part-2-slides.html#p-values-example-1",
    "href": "part-2-slides.html#p-values-example-1",
    "title": "Introduction to Statistics",
    "section": "p-values example",
    "text": "p-values example\nAs we are comparing groups, our null hypothesis is that there is no difference in the target population.\nSample mean difference: 591.12g\nStandard error of the difference: 4.23g\np-values assume that the null hypothesis is true"
  },
  {
    "objectID": "part-2-slides.html#p-value-example",
    "href": "part-2-slides.html#p-value-example",
    "title": "Introduction to Statistics",
    "section": "p-value example",
    "text": "p-value example"
  },
  {
    "objectID": "part-2-slides.html#p-value-example-1",
    "href": "part-2-slides.html#p-value-example-1",
    "title": "Introduction to Statistics",
    "section": "p-value example",
    "text": "p-value example\nThe observed sample mean difference is (591.12 - 0 \\(\\div\\) 4.23) = 139.68 standard errors away from the null hypothesis.\nThis is so far that we can’t even see it on our histogram!\nThe probability of this happening if the null were true is VERY VERY small (p &lt; 0.00000000001).\nIn this case, we would say this difference is highly significant"
  },
  {
    "objectID": "part-2-slides.html#relationship-between-p-values-and-confidence-intervals",
    "href": "part-2-slides.html#relationship-between-p-values-and-confidence-intervals",
    "title": "Introduction to Statistics",
    "section": "Relationship between p-values and confidence intervals",
    "text": "Relationship between p-values and confidence intervals\nConfidence intervals and p-values are based on the same information and so agree with one another\nIf a p-value is above 0.05, the sample estimate is less than 1.96 SEs away. This means it will be within the 95% confidence interval\nIf the null hypothesis is outside the 99% confidence interval, it is over 2.576 SEs away from the sample estimate so p &lt; 0.01"
  },
  {
    "objectID": "part-2-slides.html#section-18",
    "href": "part-2-slides.html#section-18",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "−+\n10:00"
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "A mobile phone app collects user information. Some of this data are missing as users chose to opt out of location-based services.\nGive one scenario where the missing data would lead to biased analysis results.\nGive another scenario where the missing data leads to a reduced sample but could still be used to produce unbiased results."
  },
  {
    "objectID": "exercises.html#exercise-1-missing-data",
    "href": "exercises.html#exercise-1-missing-data",
    "title": "Introduction to Statistics",
    "section": "",
    "text": "A mobile phone app collects user information. Some of this data are missing as users chose to opt out of location-based services.\nGive one scenario where the missing data would lead to biased analysis results.\nGive another scenario where the missing data leads to a reduced sample but could still be used to produce unbiased results."
  },
  {
    "objectID": "exercises.html#exercise-2-summary-statistics",
    "href": "exercises.html#exercise-2-summary-statistics",
    "title": "Introduction to Statistics",
    "section": "Exercise 2: Summary statistics",
    "text": "Exercise 2: Summary statistics\n\nQuestion 1\nThe following line graphs are taken from the Criminal Courts statistics quarterly report, showing the average number of days from offense to completion for defendants at the Crown Court. Which graph is the most appropriate to display the average time and why?\n\n\n\nAverage number of days from offence to completion for defendants dealt with at the Crown Court, Q1 2014 – Q4 2023\n\n\n\n\nQuestion 2\nThe mean and standard deviation of waiting times in weeks for hearings in the Crown Court between 2020 and 2023 are given in the table below. Using this information, what can you tell about the distribution of these times?\n\n\n\n\n\nYear\nMean wait (weeks)\nSD wait (weeks)\n\n\n\n\n2020\n13.5\n10.2\n\n\n2021\n19.1\n15.6\n\n\n2022\n20.9\n13.9\n\n\n2023\n22.8\n14.7"
  },
  {
    "objectID": "exercises.html#exercise-3-inferential-statistics",
    "href": "exercises.html#exercise-3-inferential-statistics",
    "title": "Introduction to Statistics",
    "section": "Exercise 3: Inferential statistics",
    "text": "Exercise 3: Inferential statistics\nThe output below is taken from an analysis that compared reoffending behaviour of 249 men participating with the Keyworking programme from Only Connect (OC) with those receiving standard support. More information about the findings of this report and the intervention itself can be found on the report webpage.\nComment on the way in which these results have been presented. Are the results clear? What has been done well? Is there anything you think could be improved? Do the results shown appear to be valid (from the information we are given)?"
  },
  {
    "objectID": "exercises.html#exercise-4",
    "href": "exercises.html#exercise-4",
    "title": "Introduction to Statistics",
    "section": "Exercise 4",
    "text": "Exercise 4\nBelow are outputs from 4 models aiming to answer the research question: was body mass of penguins related to flipper length.\nUsing model comparisons and checking the diagnostic tests, which model would you choose to use to answer this question and what would your answer be?\n\nlm_flipper &lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins)\nlm_flipper_sex &lt;- lm(body_mass_g ~ flipper_length_mm + sex, data = penguins)\nlm_flipper_sex_bill &lt;- lm(body_mass_g ~ flipper_length_mm + sex + bill_depth_mm, data = penguins)\nlm_bill_sex&lt;- lm(body_mass_g ~ sex + bill_depth_mm, data = penguins)\n\nmodel_output &lt;- function(model){\n  broom::tidy(model, conf.int = T) %&gt;% \n    mutate(across(is.numeric, ~round(., 2)),\n           con.int = paste0(\"[\", conf.low, \", \", conf.high, \"]\"),\n           pvalue = ifelse(p.value == 0, \"&lt;0.01\", p.value)) %&gt;% \n    select(term, estimate, con.int, pvalue) %&gt;% \n    kable(col.names = c(\"\", \"Coefficient\", \"95% CI\", \"p\"))\n}\n\nmodels &lt;- list(lm_flipper, lm_flipper_sex, lm_flipper_sex_bill, lm_bill_sex)\n\nmap(models, model_output)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(is.numeric, ~round(., 2))`.\nCaused by warning:\n! Use of bare predicate functions was deprecated in tidyselect 1.1.0.\nℹ Please use wrap predicates in `where()` instead.\n  # Was:\n  data %&gt;% select(is.numeric)\n\n  # Now:\n  data %&gt;% select(where(is.numeric))\n\n\n[[1]]\n\n\n|                  | Coefficient|95% CI              |p     |\n|:-----------------|-----------:|:-------------------|:-----|\n|(Intercept)       |    -5780.83|[-6382.36, -5179.3] |&lt;0.01 |\n|flipper_length_mm |       49.69|[46.7, 52.67]       |&lt;0.01 |\n\n[[2]]\n\n\n|                  | Coefficient|95% CI               |p     |\n|:-----------------|-----------:|:--------------------|:-----|\n|(Intercept)       |    -5410.30|[-5972.52, -4848.09] |&lt;0.01 |\n|flipper_length_mm |       46.98|[44.15, 49.82]       |&lt;0.01 |\n|sexmale           |      347.85|[268.49, 427.21]     |&lt;0.01 |\n\n[[3]]\n\n\n|                  | Coefficient|95% CI               |p     |\n|:-----------------|-----------:|:--------------------|:-----|\n|(Intercept)       |    -2246.83|[-3476.89, -1016.77] |&lt;0.01 |\n|flipper_length_mm |       38.19|[34.09, 42.29]       |&lt;0.01 |\n|sexmale           |      538.08|[437.14, 639.02]     |&lt;0.01 |\n|bill_depth_mm     |      -86.95|[-117.35, -56.54]    |&lt;0.01 |\n\n[[4]]\n\n\n|              | Coefficient|95% CI             |p     |\n|:-------------|-----------:|:------------------|:-----|\n|(Intercept)   |     8779.10|[8304.42, 9253.79] |&lt;0.01 |\n|sexmale       |     1122.13|[1009.87, 1234.4]  |&lt;0.01 |\n|bill_depth_mm |     -299.34|[-327.89, -270.8]  |&lt;0.01 |\n\nevaluations &lt;- function(model) {\n  tibble(terms = attr(model$model, \"term.labels\"),\n         adj.r = summary(model)$adj.r.squared,\n         rmse = rmse(model$model$body_mass_g, predict(model)),\n         mae = mae(model$model$body_mass_g, predict(model))) %&gt;% \n    kable()\n}\nmap(models, evaluations)\n\n[[1]]\n\n\n|     adj.r|     rmse|      mae|\n|---------:|--------:|--------:|\n| 0.7582837| 393.1236| 313.0018|\n\n[[2]]\n\n\n|     adj.r|     rmse|     mae|\n|---------:|--------:|-------:|\n| 0.8046607| 354.2762| 283.245|\n\n[[3]]\n\n\n|     adj.r|     rmse|      mae|\n|---------:|--------:|--------:|\n| 0.8212593| 338.3763| 276.4011|\n\n[[4]]\n\n\n|     adj.r|     rmse|      mae|\n|---------:|--------:|--------:|\n| 0.6399402| 480.9883| 383.8665|"
  },
  {
    "objectID": "part-1-slides.html#what-is-statistics",
    "href": "part-1-slides.html#what-is-statistics",
    "title": "Introduction to Statistics",
    "section": "What is statistics?",
    "text": "What is statistics?\n\n\nStatistics = science of data\n\nCollection and storage of data\nData visualisation\nAnalysis of data\nInterpretation of results\nCommunication of results\n\n\n\n\n\n\nStatistics is the science of data. This includes the collection and storage of data, the visualisation and analysis of samples of data, and the interpretation and communication of results."
  },
  {
    "objectID": "part-1-slides.html#what-is-statistics-1",
    "href": "part-1-slides.html#what-is-statistics-1",
    "title": "Introduction to Statistics",
    "section": "What is statistics?",
    "text": "What is statistics?\n\n\n\n\n\n\nThe overall aim of statistics is to make inferences about a target population of interest based on a random sample."
  },
  {
    "objectID": "part-1-slides.html#what-is-statistics-2",
    "href": "part-1-slides.html#what-is-statistics-2",
    "title": "Introduction to Statistics",
    "section": "What is statistics?",
    "text": "What is statistics?\n\n\n\n\n\n\nThese inferences are made by applying some kind of statistical analysis to the random sample of the population and making inferences based on those results"
  },
  {
    "objectID": "part-1-slides.html#what-is-statistical-thinking",
    "href": "part-1-slides.html#what-is-statistical-thinking",
    "title": "Introduction to Statistics",
    "section": "What is statistical thinking?",
    "text": "What is statistical thinking?\nStatistics does not require complex analysis methods\nSimplest approaches often the most effective\nStatistical thinking = data-driven critical thinking\n\nPeople tend to assume that statistics involves complex analysis methods but often, the simplest approaches can be the most effective. In this course, we will not focus on analysis methods. Instead, we will be focusing on thinking statistically.\nStatistical thinking involves describing data and complex systems in relatively simple terms whilst acknowledging uncertainty that exists. The process of statistical thinking involves critically appraising available data, identifying patterns using visualisations and summaries, and communicating results in a clear, concise manner. Statistical thinking could be thought of as data-driven critical thinking."
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking",
    "href": "part-1-slides.html#why-statistical-thinking",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\nIn 1990, 58% of the world’s population lived in low-income countries. What is the percentage today?\n\n\nAround 9%\nAround 37%\nAround 61%\n\n\n\n\nSource: Gapminder"
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking-1",
    "href": "part-1-slides.html#why-statistical-thinking-1",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\nIn 1990, 58% of the world’s population lived in low-income countries. What is the percentage today?\n\n\nAround 9%\nAround 37%\nAround 61%\n\n\n\n\nSource: Gapminder"
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking-2",
    "href": "part-1-slides.html#why-statistical-thinking-2",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\nIn low-income countries across the world in 2022, what share of girls went to school until at least age 11?\n\n\nAround 20%\nAround 40%\nAround 60%\n\n\n\n\nSource: Gapminder"
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking-3",
    "href": "part-1-slides.html#why-statistical-thinking-3",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\nIn low-income countries across the world in 2022, what share of girls went to school until at least age 11?\n\n\nAround 20%\nAround 40%\nAround 60%\n\n\n\n\nSource: Gapminder"
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking-4",
    "href": "part-1-slides.html#why-statistical-thinking-4",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\nHow many babies in the UK were vaccinated against some disease in 2019 (before the Coronavirus pandemic)?\n\n\nAround 40%\nAround 60%\nAround 90%\n\n\n\n\nSource: Gapminder"
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking-5",
    "href": "part-1-slides.html#why-statistical-thinking-5",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\nHow many babies in the UK were vaccinated against some disease in 2019 (before the Coronavirus pandemic)?\n\n\nAround 40%\nAround 60%\nAround 90%\n\n\n\n\nSource: Gapminder"
  },
  {
    "objectID": "part-1-slides.html#why-statistical-thinking-6",
    "href": "part-1-slides.html#why-statistical-thinking-6",
    "title": "Introduction to Statistics",
    "section": "Why statistical thinking?",
    "text": "Why statistical thinking?\n\n\nNecessary, not just in work but in personal life\nClaims by news/social media often exaggerated or skewed\nHuman brain have a tendency to catastrophise, not good at assessing risk"
  },
  {
    "objectID": "part-1-slides.html#course-content",
    "href": "part-1-slides.html#course-content",
    "title": "Introduction to Statistics",
    "section": "Course content",
    "text": "Course content\nPart 1: Tuesday 21st January, 2025\n\nStatistical thinking\n\nFormulating a research question\nCommon biases\nMissing data"
  },
  {
    "objectID": "part-1-slides.html#course-content-1",
    "href": "part-1-slides.html#course-content-1",
    "title": "Introduction to Statistics",
    "section": "Course content",
    "text": "Course content\nPart 1: Tuesday 21st January, 2025\n\nData exploration\n\nSummary statistics: what they are, how we choose them, and how we communicate them"
  },
  {
    "objectID": "part-1-slides.html#course-content-2",
    "href": "part-1-slides.html#course-content-2",
    "title": "Introduction to Statistics",
    "section": "Course content",
    "text": "Course content\nPart 2: Thursday 23rd January, 2025\n\nData exploration\n\nUnderstanding the sample: how to quantify differences and trends in a sample\n\nInferential statistics\n\nCentral limit theorem\nHow to interpret and communicate p-values and confidence intervals"
  },
  {
    "objectID": "part-1-slides.html#course-content-3",
    "href": "part-1-slides.html#course-content-3",
    "title": "Introduction to Statistics",
    "section": "Course content",
    "text": "Course content\nPart 3: Tuesday 28th January 2025\n\nStatistical modelling\n\nWhat are models and why are they useful to data analytics?\nHow to choose an appropriate model based on the research question\nModel outputs and their interpretations"
  },
  {
    "objectID": "part-1-slides.html#research-questions",
    "href": "part-1-slides.html#research-questions",
    "title": "Introduction to Statistics",
    "section": "Research questions",
    "text": "Research questions\nOne of the most important parts of statistical analysis\nShould be formulated before any data collection or analysis carried out\nMust be clear, answerable, and concise\nOften not formally documented but helps develop an analysis plan\n\nArguably, the most important step in carrying out statistics is to specify a clear, answerable research question. Often, research questions are not formally documented but they are key to ensuring we are using appropriate data and methods to provide the most suitable advice. A research question must be fully specified before any data are collected or any analysis plans have been decided."
  },
  {
    "objectID": "part-1-slides.html#research-questions-1",
    "href": "part-1-slides.html#research-questions-1",
    "title": "Introduction to Statistics",
    "section": "Research questions",
    "text": "Research questions\nAll research questions must contain a target population and an outcome\nOften questions contain comparison groups, these must also be fully defined\nCan be helpful to use PICO approach\n\nAlthough there are infinite research questions that statistics can be used to address, all must contain certain elements. These are a target population and an outcome of interest. If an analysis requires a comparison between groups, these must also be clearly specified in the research question. One way to ensure that a research question has been correctly specified is to use the PICO approach:"
  },
  {
    "objectID": "part-1-slides.html#pico-approach",
    "href": "part-1-slides.html#pico-approach",
    "title": "Introduction to Statistics",
    "section": "PICO approach",
    "text": "PICO approach\nPopulation\nIntervention (group 1)\nComparison (group 2)\nOutcome"
  },
  {
    "objectID": "part-1-slides.html#example-research-question",
    "href": "part-1-slides.html#example-research-question",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-1",
    "href": "part-1-slides.html#example-research-question-1",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-2",
    "href": "part-1-slides.html#example-research-question-2",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: Obese adults"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-3",
    "href": "part-1-slides.html#example-research-question-3",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: Obese adults\nPeople aged 18 or over"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-4",
    "href": "part-1-slides.html#example-research-question-4",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: Obese adults\nPeople aged 18 or over with a BMI over 30"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-5",
    "href": "part-1-slides.html#example-research-question-5",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: People aged 18 or over with a BMI over 30"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-6",
    "href": "part-1-slides.html#example-research-question-6",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: People aged 18 or over with a BMI over 30\nIntervention: Plant-based diet\nComparison: Standard diet (control group)"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-7",
    "href": "part-1-slides.html#example-research-question-7",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: People aged 18 or over with a BMI over 30\nIntervention: Plant-based diet\nComparison: Standard diet (control group)"
  },
  {
    "objectID": "part-1-slides.html#example-research-question-8",
    "href": "part-1-slides.html#example-research-question-8",
    "title": "Introduction to Statistics",
    "section": "Example research question",
    "text": "Example research question\nDoes a plant-based diet reduce cholesterol levels in obese adults?\nPopulation: People aged 18 or over with a BMI over 30\nIntervention: Plant-based diet\nComparison: Standard diet (control group)\nOutcome: Difference in cholesterol level"
  },
  {
    "objectID": "part-1-slides.html#biases",
    "href": "part-1-slides.html#biases",
    "title": "Introduction to Statistics",
    "section": "Biases",
    "text": "Biases\nAlmost all data and analyses will have some kind of bias included\nImportant to consider before analysis plan decided\nCan arise at data collection, analysis, interpretation, and communication stages\n\nWhether the data we use to answer our research question is collected by ourselves or taken from a published source, it is important to consider potential biases, or errors, that may be present. Unfortunately most data collection methods are inherently flawed, this makes it especially important to be transparent about the limitations of the data and analysis we provide.\nThere are many different types of bias that can arise at different stages of an analysis. Here, I will introduce some of the most common types with examples."
  },
  {
    "objectID": "part-1-slides.html#selection-bias",
    "href": "part-1-slides.html#selection-bias",
    "title": "Introduction to Statistics",
    "section": "Selection bias",
    "text": "Selection bias\n\n\nIndividuals more likely to be included in sample than others\nSample no longer random, cannot make inferences about target population\n\n\n\n\n\nSelection bias occurs when some data are more likely to be included in a sample than others. One of the key requirements of statistical analysis is that a sample must be random and representative of the target population in our research question. If this is not the case, we may not be able to make inferences about the target population and will not be able to answer the research question. Cherry picking individuals\nFor example, we are interested in whether one hour of yoga per day improves depressive symptoms in adults living in the UK with anxiety and depression. We ask GPs around the UK to suggest patients from their surgery that are currently being treated for anxiety and depression to take part in the study. If the doctors deliberately selected the patients they thought would benefit most from the yoga classes, i.e. those with the highest baseline depressive symptoms, this sample would not be random and the results would be impacted by selection bias."
  },
  {
    "objectID": "part-1-slides.html#recall-bias",
    "href": "part-1-slides.html#recall-bias",
    "title": "Introduction to Statistics",
    "section": "Recall bias",
    "text": "Recall bias\n\n\nParticipants asked to recall past events or experiences\nAccuracy and completeness will differ\nNot always trustworthy\n\n\n\n\n\nRecall bias occurs when participants are asked to recall past events or experiences as part of a study which will differ in accuracy and completeness. For example, in a study investigating the impact of ultra processed food on the rates of heart disease, participants were asked to recall how many ultra processed foods they had consumed in the past week. Most participants are likely to forget some of the food they had eaten over a week, and the accuracy of this recall is likely to differ between participants."
  },
  {
    "objectID": "part-1-slides.html#confirmation-bias",
    "href": "part-1-slides.html#confirmation-bias",
    "title": "Introduction to Statistics",
    "section": "Confirmation bias",
    "text": "Confirmation bias\n\n\nChoosing to analyse or interpret data based on pre-conceived ideas\nInherent to human brains\nIdentify potential expectations before looking at data\n\n\n\n\n\nConfirmation bias is the tendency to analyse or interpret data in a way that supports preconceived ideas. Unfortunately, confirmation bias is inherent to human nature and can be difficult to spot. It is also one of the reasons that statistical thinking, rather than simply trusting our gut instinct, is so important. The best way to counteract confirmation bias is to acknowledge any pre-conceived ideas or expectations of results before looking at data and being aware of these throughout the process."
  },
  {
    "objectID": "part-1-slides.html#missing-data",
    "href": "part-1-slides.html#missing-data",
    "title": "Introduction to Statistics",
    "section": "Missing data",
    "text": "Missing data\n\n\nMissing data = holes in the dataset\nSomething we intended to collect but have not\nVery common, not always obvious\nPotential source of bias\n\n\n\n\n\nAnother potential source of bias comes from the existence of missing data. Missing data are observations that were intended to be collected but were not. Unfortunately they are very common in analysis, even when every effort has been made to avoid them. Examples of missing data include:"
  },
  {
    "objectID": "part-1-slides.html#examples-of-missing-data",
    "href": "part-1-slides.html#examples-of-missing-data",
    "title": "Introduction to Statistics",
    "section": "Examples of missing data",
    "text": "Examples of missing data\n\nQuestionnaires not complete as some questions are considered too personal by participants\nBlood samples are dropped in a lab, losing the results, leaving holes in the data\nUser information collected from a mobile phone app includes location data for some but is missing for others who opted-out of sharing this data\n\n\n\nA questionnaire is sent out to households in a local authority, asked for information about household income and employment history. Some households consider these questions too personal and did not fill in the information.\nA clinical trial involves taking blood samples from participants to analyse. Some samples are dropped on the way to the lab and their results are unusable. The analysis dataset contains blank spaces where these results would be.\nMobile phone apps that collect user information often have holes in the dataset where users opt-out of data sharing"
  },
  {
    "objectID": "part-1-slides.html#missing-data-1",
    "href": "part-1-slides.html#missing-data-1",
    "title": "Introduction to Statistics",
    "section": "Missing data",
    "text": "Missing data\nImpossible to truly know the reason for and impact of missing data\nBest way to overcome missing data is to not have any!\nImportant to consider potential biases introduced by missing data and account for them in analysis\nBe transparent when reporting missing data\n\nUnfortunately, the true reason for missingness will not be known as the data do not exist. When dealing with missing data, our main aim is to identify the most likely reasons and be transparent about the implication of this on our analysis. Failure to recognise and deal with missing data can produce invalid, often misleading results. If data are missing because of the missing data itself, or if there would be systematic differences between the observed and missing values, this means the data are no longer random, one of the main requirements of statistical inference. At a very minimum, we must be transparent about the number and type of missing data within our sample. This should be done before analysis methods are considered as sometimes they may require alternative approaches to overcome the bias introduced by missingness."
  },
  {
    "objectID": "part-1-slides.html#missing-data-and-bias",
    "href": "part-1-slides.html#missing-data-and-bias",
    "title": "Introduction to Statistics",
    "section": "Missing data and bias",
    "text": "Missing data and bias\nUser information is collected from a mobile phone app.\nThere are a number of users that do not have spatial location data as they opted out of this data collection.\nIn groups, come up with two scenarios:"
  },
  {
    "objectID": "part-1-slides.html#missing-data-and-bias-1",
    "href": "part-1-slides.html#missing-data-and-bias-1",
    "title": "Introduction to Statistics",
    "section": "Missing data and bias",
    "text": "Missing data and bias\n\n\nA situation where this missing data may introduce bias into analysis results\nA situation where the sample size is reduced, but this does not lead to bias in analysis results.\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "part-1-slides.html#summarising-data",
    "href": "part-1-slides.html#summarising-data",
    "title": "Introduction to Statistics",
    "section": "Summarising data",
    "text": "Summarising data\nAllows us to explore and quantify aspects of the sample\nCan not be used to answer research question unless all information on target population is collected\nChoice of summary depends on type of variable, distribution of data, and property we wish to quantify\n\nSummary statistics allow us to quantify and explore different parts of a sample of data. They can be provided alongside data visualisations introduced earlier in the course to support results and interpretations. Note that the summary statistics introduced in this section describe only the sample data so cannot be used to answer research questions fully unless all data on the target population has been collected.\nThe choice of summary statistics will depend on the type of variable(s) we wish to explore, the distribution of these variable(s) and the aspect of the data we would like to quantify. When interpreting summaries provided from analysis that has already been completed, it is important to check that the most appropriate summaries have been used and that interpretations of them will be valid."
  },
  {
    "objectID": "part-1-slides.html#introducing-the-palmer-penguins",
    "href": "part-1-slides.html#introducing-the-palmer-penguins",
    "title": "Introduction to Statistics",
    "section": "Introducing the Palmer penguins",
    "text": "Introducing the Palmer penguins\n\nArtwork by @allison_horst\nFrom this point on, we will be using data collected on penguins that live in the Palmer peninsula in Antarctica. The data contains information about the size and shape of these penguins, their gender and the species of penguin."
  },
  {
    "objectID": "part-1-slides.html#introducing-the-palmer-penguins-1",
    "href": "part-1-slides.html#introducing-the-palmer-penguins-1",
    "title": "Introduction to Statistics",
    "section": "Introducing the Palmer penguins",
    "text": "Introducing the Palmer penguins\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nChinstrap\nDream\n45.5\n17.0\n196\n3500\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.2\n216\n5000\nfemale\n2009\n\n\nGentoo\nBiscoe\n46.6\n14.2\n210\n4850\nfemale\n2008\n\n\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nfemale\n2007\n\n\nChinstrap\nDream\n49.5\n19.0\n200\n3800\nmale\n2008\n\n\nAdelie\nTorgersen\n36.2\n17.2\n187\n3150\nfemale\n2009"
  },
  {
    "objectID": "part-1-slides.html#summarising-categorical-variables",
    "href": "part-1-slides.html#summarising-categorical-variables",
    "title": "Introduction to Statistics",
    "section": "Summarising categorical variables",
    "text": "Summarising categorical variables\nDescribe the distribution of observations between categories:\n\nProportion (0 → 1)\nPercentage (0 → 100%)\nRate (0 → ∞)\n\nCan use count but does not account for overall sample size\n\nTo summarise a single categorical variable, we simply need to quantify the distribution of observations lying in each group. The simplest way to do this is to count the number of observations that lie in each group, as we have seen previously displayed in frequency tables. However, a simple count can be difficult to interpret without proper context. Often, we wish to present these counts relative to the total sample that they are taken from.\nThe proportion of observations in a given group is estimated as the number in the group divided by the total sample size. This gives a value between 0 and 1. Multiplying the proportion by 100 will give the percentage in each group, taking the value between 0 and 100%. In cases where the proportion and percentage in a given group is very small, we may wish to multiply the proportions by a larger number to make values easier to interpret. These values are known as rates and are interpreted as the value per the number multiplied by. For example, if the proportion in a group was 0.0005, this could be multiplied by 10,000 to give a rate of 5 per 10,000."
  },
  {
    "objectID": "part-1-slides.html#summarising-categorical-variables-1",
    "href": "part-1-slides.html#summarising-categorical-variables-1",
    "title": "Introduction to Statistics",
    "section": "Summarising categorical variables",
    "text": "Summarising categorical variables\nExample: the distribution of penguins between species in the sample data.\n\nTotal number of penguins in the sample: 344\nTotal number of Adelie penguins: 152\n\nProportion: 152 \\(\\div\\) 344 = 0.4419\nPercentage: 0.4419 \\(\\times\\) 100% = 44.19%\nRate: 0.4419 \\(\\times\\) 10,000 = 4419 per 10,000 penguins."
  },
  {
    "objectID": "part-1-slides.html#summarising-numeric-variables",
    "href": "part-1-slides.html#summarising-numeric-variables",
    "title": "Introduction to Statistics",
    "section": "Summarising numeric variables",
    "text": "Summarising numeric variables\nSummarised using the centre (average) and spread of sample\n\nChoice of summary depends on the distribution of variable\n\n\n\n\n\n\n\n\n\n\n\nNumeric variables are typically summarised using the centre of the variable, also known as the average, and a measure of the spread of the variable. The most appropriate choice of summary statistics will depend on the distribution of the variable. More specifically, whether the numeric variable is normally distributed or not. The shape/distribution of a variable is typically investigated by plotting data in a histogram."
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre",
    "href": "part-1-slides.html#measure-of-centre",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nWhen data are normally distributed, centre is given using the mean\n\n\nRepresents the peak of a normal distribution\nSum of the sample values, divided by the sample size\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe average of a numeric variable is another way of saying the centre of its distribution. Often, people will think of the mean when trying to calculate an average, however this may not always be the case. When data are normally distributed, the mean is the central peak of the distribution. This is calculated by adding together all numbers in the sample and dividing it by the sample size."
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-1",
    "href": "part-1-slides.html#measure-of-centre-1",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nTake a random sample of 10 penguins from our data and measure their bill length (in mm):\n40.3, 38.8, 35.5, 42, 39.8, 46.1, 38.6, 46.7, 40.9, 38.6\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-2",
    "href": "part-1-slides.html#measure-of-centre-2",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nFind the mean bill length:\n40.3 + 38.8 + 35.5 + 42 + 39.8 + 46.1 + 38.6 + 46.7 + 40.9 + 38.6\n= 407.3mm\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-3",
    "href": "part-1-slides.html#measure-of-centre-3",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nFind the mean bill length:\n407.3 \\(\\div\\) 10 = 40.73mm\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-center",
    "href": "part-1-slides.html#measure-of-center",
    "title": "Introduction to Statistics",
    "section": "Measure of center",
    "text": "Measure of center\nWhere data are not normal, use median instead\nOrder sample from smallest to largest, select middle value\nUses less information than mean (less powerful) but always valid\n\nHowever, when the sample is not normally distributed and the peak does not lie in the middle, extreme values or a longer tail will pull the mean towards it. This means that where data are not normally distributed, the mean will not be the centre and the value will be invalid. Where this is the case, the median should be used instead. The median is calculated by ordering the numeric values from smallest to largest and selecting the middle value."
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-4",
    "href": "part-1-slides.html#measure-of-centre-4",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nTo find the median, first order bill lengths smallest to largest:\n40.3, 38.8, 35.5, 42, 39.8, 46.1, 38.6, 46.7, 40.9, 38.6\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-5",
    "href": "part-1-slides.html#measure-of-centre-5",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nTo find the median, first order bill lengths smallest to largest:\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-6",
    "href": "part-1-slides.html#measure-of-centre-6",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nThe median is the middle value\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst\n\n\n\nWe then take the middle value. As the sample size is even, the median will lie between two values - the 5th (149.58cm) and the 6th (160.42cm)."
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-7",
    "href": "part-1-slides.html#measure-of-centre-7",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nMedian is between 39.8mm and 40.3mm.\nMiddle value: (39.8 + 40.3) \\(\\div\\) 2 = 40.05mm\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-centre-8",
    "href": "part-1-slides.html#measure-of-centre-8",
    "title": "Introduction to Statistics",
    "section": "Measure of centre",
    "text": "Measure of centre\nBefore choosing summary, use a histogram to check distribution\nWhen data are normally distributed, mean uses more of the data and gives centre of the sample\nWhen data are skewed, mean is influenced by extreme values and longer tail\nWhen data are normal, mean and median will be equal\n\nWhen data are normally distributed, the mean and median will give the same, or very similar, values. This is because both are measuring the centre. However, when the data are skewed, the mean and median will differ. We prefer to use the mean where possible as it is the more powerful measure. This means that it uses more of the data than the median and is therefore more sensitive to changes in the sample."
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread",
    "href": "part-1-slides.html#measure-of-spread",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nMeasures how wide or narrow a sample is\nSimplest measure is the range\nEither given as the smallest and largest values or the difference between these\n\nGenerally the measure of the centre of a numeric variable is presented with a measure of spread, or how wide/narrow the distribution is. As with the centre, the most appropriate values will depend on whether the sample is normally distributed or not.\nThe most simple measure of spread is the range of a sample. The range is either presented as the smallest and largest values from a sample or the difference between these."
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-1",
    "href": "part-1-slides.html#measure-of-spread-1",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the range of the 10 penguins’ bill lengths:\n40.3, 38.8, 35.5, 42, 39.8, 46.1, 38.6, 46.7, 40.9, 38.6\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-2",
    "href": "part-1-slides.html#measure-of-spread-2",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the range of the 10 penguins’ bill lengths:\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-3",
    "href": "part-1-slides.html#measure-of-spread-3",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the range of the 10 penguins’ bill lengths:\n35.5 , 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-4",
    "href": "part-1-slides.html#measure-of-spread-4",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nRange is either given as two values: 35.5mm, 46.7mm\nOr as the difference between these: 46.7 - 35.5 = 11.2mm\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-5",
    "href": "part-1-slides.html#measure-of-spread-5",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nRange only uses most extreme values, loses lots of information\nInterquartile range (IQR): the range of the middle 50%\nLower quartile: 25th percentile, 25% of sample lies below\nUpper quartile: 75th percentile, 75% of sample lies below\n\nThe issue with using the range is that it is entirely defined by the most extreme values in the sample and does not give any information about the rest of it. An alternative to this would be to give the range of the middle 50%, also known as the interquartile range (IQR). The IQR is the difference between the 75th percentile, or upper quartile, and the 25th percentile, or lower quartile."
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-6",
    "href": "part-1-slides.html#measure-of-spread-6",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the IQR of the 10 penguins’ bill lengths:\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-7",
    "href": "part-1-slides.html#measure-of-spread-7",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the upper and lower quartile:\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-8",
    "href": "part-1-slides.html#measure-of-spread-8",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the upper and lower quartile:\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-9",
    "href": "part-1-slides.html#measure-of-spread-9",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nFind the upper and lower quartile:\n35.5, 38.6, 38.6, 38.8, 39.8, 40.3, 40.9, 42, 46.1, 46.7\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-10",
    "href": "part-1-slides.html#measure-of-spread-10",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nIQR is either given as 2 values: 38.6mm, 42mm\nOr as the difference between these: 42 - 38.6 = 3.4mm\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "part-1-slides.html#measure-of-spread-11",
    "href": "part-1-slides.html#measure-of-spread-11",
    "title": "Introduction to Statistics",
    "section": "Measure of spread",
    "text": "Measure of spread\nIQR is still discarding most of the sample\nIf sample is normally distributed, can use the standard deviation (SD)\nAverage difference between observations and the mean\nBigger SD → wider, flatter curve\nSmaller SD → narrower, taller curve\n\nBoth the range and IQR only use 2 values from the sample. As with the median, these measures discard a lot of information from the summaries. Where the sample is normally distributed, the standard deviation (SD) can be used which measures the average distance between each observation and the mean. The larger the SD, the wider and flatter the normal curve will be; the smaller the SD, the narrower and taller the curve will be:"
  },
  {
    "objectID": "part-1-slides.html#normal-distribution",
    "href": "part-1-slides.html#normal-distribution",
    "title": "Introduction to Statistics",
    "section": "Normal distribution",
    "text": "Normal distribution\nNormal distribution completely defined by the mean (peak) and SD (spread)\n\n\nThe standard deviation is only appropriate where a numeric variable has a normal distribution, otherwise this value is meaningless. If a sample is normally distributed, then the entire sample can be completely described just using the mean and standard deviation, even when the sample values are not given. As the distribution is symmetrical, the mean and standard deviation can be used to estimate ranges of values.\nFor example, it is known that approximately 68% of a sample will lie one standard deviation from the mean, approximately 95% within 2 standard deviations from the mean, and around 99.7% within 3 standard deviations:"
  },
  {
    "objectID": "part-1-slides.html#normal-distribution-1",
    "href": "part-1-slides.html#normal-distribution-1",
    "title": "Introduction to Statistics",
    "section": "Normal distribution",
    "text": "Normal distribution\nApproximately 68% of the sample will lie within 1 standard deviation of the mean\n\n\nThe standard deviation is only appropriate where a numeric variable has a normal distribution, otherwise this value is meaningless. If a sample is normally distributed, then the entire sample can be completely described just using the mean and standard deviation, even when the sample values are not given. As the distribution is symmetrical, the mean and standard deviation can be used to estimate ranges of values.\nFor example, it is known that approximately 68% of a sample will lie one standard deviation from the mean, approximately 95% within 2 standard deviations from the mean, and around 99.7% within 3 standard deviations:"
  },
  {
    "objectID": "part-1-slides.html#normal-distribution-2",
    "href": "part-1-slides.html#normal-distribution-2",
    "title": "Introduction to Statistics",
    "section": "Normal distribution",
    "text": "Normal distribution\nApproximately 95% of the sample will lie within 2 standard deviations of the mean\n\n\nThe standard deviation is only appropriate where a numeric variable has a normal distribution, otherwise this value is meaningless. If a sample is normally distributed, then the entire sample can be completely described just using the mean and standard deviation, even when the sample values are not given. As the distribution is symmetrical, the mean and standard deviation can be used to estimate ranges of values. For example, it is known that approximately 68% of a sample will lie one standard deviation from the mean, approximately 95% within 2 standard deviations from the mean, and around 99.7% within 3 standard deviations:"
  },
  {
    "objectID": "part-1-slides.html#normal-distribution-3",
    "href": "part-1-slides.html#normal-distribution-3",
    "title": "Introduction to Statistics",
    "section": "Normal distribution",
    "text": "Normal distribution\nMean and SD can be used to check normal distribution assumption"
  },
  {
    "objectID": "part-1-slides.html#normal-distribution-4",
    "href": "part-1-slides.html#normal-distribution-4",
    "title": "Introduction to Statistics",
    "section": "Normal distribution",
    "text": "Normal distribution\nMean and SD can be used to check normal distribution assumption\nMean SFA: 37.37\nSD SFA: 78.38\nIf the data was normally distributed, 95% of the sample would lie between 37.37 \\(\\pm\\) 2 \\(\\times\\) 78.38\n= -119.39, 194.13"
  },
  {
    "objectID": "part-1-slides.html#summarising-numeric-variables-1",
    "href": "part-1-slides.html#summarising-numeric-variables-1",
    "title": "Introduction to Statistics",
    "section": "Summarising numeric variables",
    "text": "Summarising numeric variables\nMost appropriate summary depends on distribution (normal or not)\nIf normally distributed, use mean and SD\nIf not, these are invalid, use median and IQR\nMean and SD can be used to check normal distribution even without the full sample"
  },
  {
    "objectID": "part-1-slides.html#summarising-data-1",
    "href": "part-1-slides.html#summarising-data-1",
    "title": "Introduction to Statistics",
    "section": "Summarising data",
    "text": "Summarising data"
  },
  {
    "objectID": "part-1-slides.html#summarising-data-2",
    "href": "part-1-slides.html#summarising-data-2",
    "title": "Introduction to Statistics",
    "section": "Summarising data",
    "text": "Summarising data\n\n\n\n−+\n10:00\n\n\n\n\n\n\nYear\nMean wait (weeks)\nSD wait (weeks)\n\n\n\n\n2020\n13.5\n10.2\n\n\n2021\n19.1\n15.6\n\n\n2022\n20.9\n13.9\n\n\n2023\n22.8\n14.7\n\n\n\n\n\n\nThe first graph is taken from the Criminal Courts statistics quarterly report, showing the average number of days from offense to completion for defendants at the Crown Court. Which graph is the most appropriate to display the average time and why?\nThe table provides the mean and standard deviation of waiting times in weeks for hearings in the Crown Court between 2020 and 2023. Using this information, what can you tell about the distribution of these times?"
  },
  {
    "objectID": "part-3-slides.html#inferential-statistics",
    "href": "part-3-slides.html#inferential-statistics",
    "title": "Introduction to Statistics",
    "section": "Inferential statistics",
    "text": "Inferential statistics\nNow we know how to interpret and communicate inferential statistics…how do we calculate them?\nAlmost all parameters that we can estimate from a sample can be presented with inferential statistics.\n\n\n\nMean\nProportion/percentage\nCorrelation coefficients\n\n\n\nDifference in means\nDifference in proportions\nModel coefficients"
  },
  {
    "objectID": "part-3-slides.html#statistical-models",
    "href": "part-3-slides.html#statistical-models",
    "title": "Introduction to Statistics",
    "section": "Statistical models",
    "text": "Statistical models\nModels aim to explain complex process in a simple way.\nStatistical models explain these processes using a mathematical equation:\n\\(g\\)(Y) = \\(\\alpha\\) + \\(\\beta_1X_1\\) + \\(\\dots\\) + \\(\\beta_nX_n\\)\nModel equations generally consist of"
  },
  {
    "objectID": "part-3-slides.html#statistical-models-1",
    "href": "part-3-slides.html#statistical-models-1",
    "title": "Introduction to Statistics",
    "section": "Statistical models",
    "text": "Statistical models\nModels aim to explain complex process in a simple way.\nStatistical models explain these processes using a mathematical equation:\n\\(g\\)(Y) = \\(\\alpha\\) + \\(\\beta_1X_1\\) + \\(\\dots\\) + \\(\\beta_nX_n\\)\nModel equations generally consist of outcome(s),"
  },
  {
    "objectID": "part-3-slides.html#statistical-models-2",
    "href": "part-3-slides.html#statistical-models-2",
    "title": "Introduction to Statistics",
    "section": "Statistical models",
    "text": "Statistical models\nModels aim to explain complex process in a simple way.\nStatistical models explain these processes using a mathematical equation:\n\\(g\\)(Y) = \\(\\alpha\\) + \\(\\beta_1\\)\\(X_1\\) + \\(\\dots\\) + \\(\\beta_n\\)\\(X_n\\)\nModel equations generally consist of outcome(s), predictor(s)"
  },
  {
    "objectID": "part-3-slides.html#statistical-models-3",
    "href": "part-3-slides.html#statistical-models-3",
    "title": "Introduction to Statistics",
    "section": "Statistical models",
    "text": "Statistical models\nModels aim to explain complex process in a simple way.\nStatistical models explain these processes using a mathematical equation:\n\\(g\\)(Y) = \\(\\alpha\\) + \\(\\beta_1\\)\\(X_1\\) + \\(\\dots\\) + \\(\\beta_n\\)\\(X_n\\)\nModel equations generally consist of outcome(s), predictor(s) and coefficients"
  },
  {
    "objectID": "part-3-slides.html#statistical-vs-machine-learning-models",
    "href": "part-3-slides.html#statistical-vs-machine-learning-models",
    "title": "Introduction to Statistics",
    "section": "Statistical vs machine learning models",
    "text": "Statistical vs machine learning models\n\n\nMachine learning models (MLM) are very powerful when making predictions.\nHowever, the way they get these predictions is often shrouded in mystery\nModels are not interpretable"
  },
  {
    "objectID": "part-3-slides.html#statistical-vs-machine-learning-models-1",
    "href": "part-3-slides.html#statistical-vs-machine-learning-models-1",
    "title": "Introduction to Statistics",
    "section": "Statistical vs machine learning models",
    "text": "Statistical vs machine learning models\n\n\nStatistical models are based on probabilistic assumptions\nMakes them stricter but interpretable\nStatistical models are better at explaining and understanding processes"
  },
  {
    "objectID": "part-3-slides.html#regression-models",
    "href": "part-3-slides.html#regression-models",
    "title": "Introduction to Statistics",
    "section": "Regression models",
    "text": "Regression models\nCommon statistical model are regression models.\nAlso known as linear models, generalised linear models or GLMs\nChoice of regression type depends on the type of outcome variable(s).\nAll aim to fit a linear equation to a transformation of the outcome (\\(g(Y)\\))"
  },
  {
    "objectID": "part-3-slides.html#regression-models-1",
    "href": "part-3-slides.html#regression-models-1",
    "title": "Introduction to Statistics",
    "section": "Regression models",
    "text": "Regression models\n\n\n\n\n\nOutcome type\nRegression\nTransformation\n\n\n\n\nContinuous\nLinear\nIdentity\n\n\nCount/rate\nPoisson\nLog\n\n\nBinary\nLogistic\nLogit\n\n\nOrdinal\nOrdinal logistic\nLogit\n\n\nNominal\nMultinomial\nLogit"
  },
  {
    "objectID": "part-3-slides.html#linear-regression",
    "href": "part-3-slides.html#linear-regression",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nThe simplest statistical modelling approach is a linear model.\nThis is because coefficient estimates are related to the outcome itself:\n\\(Y = \\alpha + \\beta_1X_1 + \\dots\\)\nWhen \\(X_1\\) is the only predictor and a continuous variable, linear regression fits a straight line to the data"
  },
  {
    "objectID": "part-3-slides.html#linear-regression-1",
    "href": "part-3-slides.html#linear-regression-1",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nLet’s fit a model to explore the relationship between penguin’s body mass and flipper length."
  },
  {
    "objectID": "part-3-slides.html#linear-regression-2",
    "href": "part-3-slides.html#linear-regression-2",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nLet’s fit a model to explore the relationship between penguin’s body mass and flipper length.\nHere, the outcome is body mass and the predictor is flipper length:\nBody mass = \\(\\alpha\\) + \\(\\beta \\times\\) flipper length\n\n\n\n\\(\\alpha\\) = intercept\nPredicted outcome where predictors = 0\n\n\n\n\\(\\beta\\) = slope\nExpected change in outcome for a unit increase in predictor"
  },
  {
    "objectID": "part-3-slides.html#linear-regression-3",
    "href": "part-3-slides.html#linear-regression-3",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nBody mass = -5780.83 + 49.69 \\(\\times\\) flipper length\n\n\nCoefficient estimates95% confidence intervalp-valueIntercept-5,780.83[-6382.36, -5179.3]&lt;0.001Flipper length49.69[46.7, 52.67]&lt;0.001"
  },
  {
    "objectID": "part-3-slides.html#linear-regression-4",
    "href": "part-3-slides.html#linear-regression-4",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nBody mass = -5780.83 + 49.69 \\(\\times\\) flipper length"
  },
  {
    "objectID": "part-3-slides.html#linear-regression-5",
    "href": "part-3-slides.html#linear-regression-5",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nBody mass = -5780.83 + 49.69 \\(\\times\\) flipper length\n\nIntercept = -5780.83\n\nPenguins with flipper length of 0mm had a predicted body mass of -5780.83g\n\nSlope = 49.69\n\nFor every unit increase in flipper length (1mm), body mass was expected to increase by 49.69g"
  },
  {
    "objectID": "part-3-slides.html#linear-regression-6",
    "href": "part-3-slides.html#linear-regression-6",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\nConfidence intervals give a range of values the coefficients are compatible with.\nIn this sample, the average increase in body mass for every 1mm increase in flipper length was 49.69g\nBut at the population level, we are 95% confident that this increase could lie between 46.7g and 52.67g"
  },
  {
    "objectID": "part-3-slides.html#linear-regression-7",
    "href": "part-3-slides.html#linear-regression-7",
    "title": "Introduction to Statistics",
    "section": "Linear regression",
    "text": "Linear regression\np-values test the null hypothesis of no association: \\(\\beta\\) = 0\nThese p-values are both too small to be printed in their entirety, therefore the coefficients are statistically significant\nFor intercept, this has no real use.\nFor the slope, we have shown a significant association between flipper length and body mass"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression",
    "href": "part-3-slides.html#multiple-regression",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nOne of the benefits of using a regression is that we can take account of confounders\nConfounders = background variables that are related to both the outcome and predictor variable(s)\nConfounders can create false associations or hide true associations if not properly accounted for"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression-1",
    "href": "part-3-slides.html#multiple-regression-1",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nOne of the benefits of using a regression is that we can take account of confounders"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression-2",
    "href": "part-3-slides.html#multiple-regression-2",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nOne of the benefits of using a regression is that we can take account of confounders"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression-3",
    "href": "part-3-slides.html#multiple-regression-3",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nLet’s extend the previous model to account for the sex of penguins:"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression-4",
    "href": "part-3-slides.html#multiple-regression-4",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nLet’s extend the previous model to account for the sex of penguins:\nBody mass = \\(\\alpha\\) + \\(\\beta_1 \\times\\) flipper length + \\(\\beta_2 \\times\\) male\nCategorical variables are added as dummy variables\n\n\nmale = 1 if sex = male\n\nmale = 0 if sex = female"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression-5",
    "href": "part-3-slides.html#multiple-regression-5",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nBody mass = -5410.3 + 46.98 \\(\\times\\) flipper length + 347.85 \\(\\times\\) male\n\n\nCoefficient estimates95% confidence intervalp-valueIntercept-5,410.30[-5972.52, -4848.09]&lt;0.001Flipper length46.98[44.15, 49.82]&lt;0.001Male347.85[268.49, 427.21]&lt;0.001"
  },
  {
    "objectID": "part-3-slides.html#multiple-regression-6",
    "href": "part-3-slides.html#multiple-regression-6",
    "title": "Introduction to Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nBody mass = -5410.3 + 46.98 \\(\\times\\) flipper length + 347.85 \\(\\times\\) male\nCoefficients now represent expected change in outcome for unit increase in predictor after adjusting for other predictors\nThere is a significant positive association between flipper length and body mass after adjusting for differences between sexes"
  },
  {
    "objectID": "part-3-slides.html#model-evaluation",
    "href": "part-3-slides.html#model-evaluation",
    "title": "Introduction to Statistics",
    "section": "Model evaluation",
    "text": "Model evaluation\nThere are going to be many potential models to answer our research question…how do we choose the best one??\n\nConsider the intention of the model\nUse common sense and prior knowledge\nAim to find the most parsimonious"
  },
  {
    "objectID": "part-3-slides.html#model-evaluation-1",
    "href": "part-3-slides.html#model-evaluation-1",
    "title": "Introduction to Statistics",
    "section": "Model evaluation",
    "text": "Model evaluation\nModel evaluation can involve comparisons of model fitting statistics.\nR-squared value: proportion of the outcome explained by the model\nAdjusted R-squared penalises the R-squared value based on the number of predictors included in the model"
  },
  {
    "objectID": "part-3-slides.html#model-evaluation-2",
    "href": "part-3-slides.html#model-evaluation-2",
    "title": "Introduction to Statistics",
    "section": "Model evaluation",
    "text": "Model evaluation\nAdjusted R-squared value for flipper-only model: 0.76\nAdjusted R-squared value for flipper + sex model: 0.8\nAdding sex still increased the adjusted R-squared value, indicating its addition was worthwhile"
  },
  {
    "objectID": "part-3-slides.html#model-evaluation-3",
    "href": "part-3-slides.html#model-evaluation-3",
    "title": "Introduction to Statistics",
    "section": "Model evaluation",
    "text": "Model evaluation\nPrediction metrics are another family of useful model evaluation tools\nThey compare the observed outcome with the fitted model predictions.\n\nRMSE: root mean squared error \\(\\sqrt{\\frac{1}{n}\\sum{(y_i - \\hat{y}_i)^2}}\\)\nMAE: mean absolute error \\(\\frac{1}{n}\\sum|y_i - \\hat{y}_i|\\)\n\nUseful as they provide a measure of fit in context"
  },
  {
    "objectID": "part-3-slides.html#model-evaluation-4",
    "href": "part-3-slides.html#model-evaluation-4",
    "title": "Introduction to Statistics",
    "section": "Model evaluation",
    "text": "Model evaluation\n\n\n\n\n\nModel\nRMSE\nMAE\n\n\n\n\nFlipper only\n393.12\n313.00\n\n\nFlipper + sex\n354.28\n283.25\n\n\n\n\n\nAdding sex into the model reduced performance metrics. This means it improved prediction.\nIf both prediction errors are large (in context of the problem), consider trying to improve them in some way"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics",
    "href": "part-3-slides.html#model-diagnostics",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nLinear regression is a parametric method: it has assumptions that must be checked\n\nLinearity: can present the outcome as a linear combination of predictors\nIndependent predictors: no multicollinearity present\nNormally distributed residuals\nEqual variance of residuals AKA homoskedasticity"
  },
  {
    "objectID": "part-3-slides.html#model-diagnistics",
    "href": "part-3-slides.html#model-diagnistics",
    "title": "Introduction to Statistics",
    "section": "Model diagnistics",
    "text": "Model diagnistics\nPredictors must be independent of one another.\nCorrelation can be accounted for to some degree, and dependency can exist between &gt; 2 variables\nVariance inflation factor (VIF): Measure of multicollinearity\n\\(VIF_i = \\frac{1}{1 - R_i^2}\\) for each predictor"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics-1",
    "href": "part-3-slides.html#model-diagnostics-1",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nVIF = 10 → \\(R^2 = 0.9\\): 90% of the variation in that predictor is explained by other predictors\nMulticollinearity leads to unstable coefficient estimates and invalid inferential statistics\nWhen there is evidence of multicollinearity (VIF &gt; 5-ish), remove the offending variable(s)!"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics-2",
    "href": "part-3-slides.html#model-diagnostics-2",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nResiduals = model error terms: observed outcome - predicted outcome\nUsed to check final three assumptions:\n\nLinearity: plot residuals against each predictor\nNormal distribution: plot a histogram of residuals\nEqual variance: plot residuals against the predicted outcome"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics-3",
    "href": "part-3-slides.html#model-diagnostics-3",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nLinearity: check residual vs. predictor plots for patterns"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics-4",
    "href": "part-3-slides.html#model-diagnostics-4",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nLinearity: check residual vs. predictor plots for patterns"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics-5",
    "href": "part-3-slides.html#model-diagnostics-5",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nNormally distribution residuals"
  },
  {
    "objectID": "part-3-slides.html#model-diagnostics-6",
    "href": "part-3-slides.html#model-diagnostics-6",
    "title": "Introduction to Statistics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\nHomoskedasticity: check residual vs. prediction plots for patterns"
  },
  {
    "objectID": "part-3-slides.html#generalised-linear-models",
    "href": "part-3-slides.html#generalised-linear-models",
    "title": "Introduction to Statistics",
    "section": "Generalised linear models",
    "text": "Generalised linear models\nWhen the outcome variable is not continuous, another regression model must be chosen.\nEstimated coefficients relate to a transformed version of the outcome.\nFor example, a fitted poisson model (of counts) looks like this:\n\\(log(Y) = \\alpha + \\beta_1X_1 + \\beta_2X_2 + \\dots\\)\nCoefficients (\\(\\alpha\\), \\(\\beta_1\\), \\(\\beta_2\\)) relate to the log of the outcome."
  },
  {
    "objectID": "part-3-slides.html#generalised-linear-models-1",
    "href": "part-3-slides.html#generalised-linear-models-1",
    "title": "Introduction to Statistics",
    "section": "Generalised linear models",
    "text": "Generalised linear models\nTo interpret coefficients, they must be back-transformed to relate to the original outcome.\nFor example, in the poisson case, we apply the exponential function (the opposite of the log) to the equation\nThis makes interpretation of other regression models slightly more difficult but not impossible!"
  },
  {
    "objectID": "part-3-slides.html#generalised-linear-models-2",
    "href": "part-3-slides.html#generalised-linear-models-2",
    "title": "Introduction to Statistics",
    "section": "Generalised linear models",
    "text": "Generalised linear models\nStatistical models are based on probabilistic assumptions.\nThese assumptions must be true for results for be valid\nDifferent regression types have different assumptions but all share these two:\n1. Observations must be independent of one another\n2. It must be possible to represent the relationship between the (transformed) outcome and predictors using a linear equation"
  },
  {
    "objectID": "part-3-slides.html#beyond-glms",
    "href": "part-3-slides.html#beyond-glms",
    "title": "Introduction to Statistics",
    "section": "Beyond GLMs",
    "text": "Beyond GLMs\nWhen either of these assumptions are not valid, we must consider other models\nMixed models (or GLMM, multilevel models, random effect models) account for dependency structures in data:\n\n\n\nSpatial data\nTemporal data\n\n\n\nData on clusters (e.g. households)"
  },
  {
    "objectID": "part-3-slides.html#beyond-glms-1",
    "href": "part-3-slides.html#beyond-glms-1",
    "title": "Introduction to Statistics",
    "section": "Beyond GLMs",
    "text": "Beyond GLMs\nWhen either of these assumptions are not valid, we must consider other models\nAdditive models (GAMs) are useful when modelling non-linear relationships\nAllow smooth functions of predictors, \\(s(X)\\), to be entered into a model:\ng(Y) = \\(\\alpha + \\beta_1X_1 + \\dots + s(X_j)\\)"
  },
  {
    "objectID": "part-3-slides.html#final-thoughts",
    "href": "part-3-slides.html#final-thoughts",
    "title": "Introduction to Statistics",
    "section": "Final thoughts",
    "text": "Final thoughts\n\nStatistics is a huge topic\nDo not underestimate planning stage: research questions, biases and exploratory work\nComplex analysis can not overcome bad data\nDo not make inferential statements about sample estimates and do not make causal statements unless performing causal analysis"
  },
  {
    "objectID": "part-3-slides.html#final-thoughts-1",
    "href": "part-3-slides.html#final-thoughts-1",
    "title": "Introduction to Statistics",
    "section": "Final thoughts",
    "text": "Final thoughts\n\nChoose analysis methods based on the research question rather than the available data\nModels should be built to address this question and using common sense/background knowledge not based on p-values\nIf a method requires assumptions to be met, check these before communicating results"
  },
  {
    "objectID": "part-3-slides.html#final-thoughts-2",
    "href": "part-3-slides.html#final-thoughts-2",
    "title": "Introduction to Statistics",
    "section": "Final thoughts",
    "text": "Final thoughts\n\nMany free statistical software packages available\nR is a favourite of statisticians (me included!) and has a huge online community to help learn and TONS of free resources\nPython is a favourite of data scientists and has a rapidly growing community\nExcel will do basic stats but is limited and prone to issues!"
  }
]