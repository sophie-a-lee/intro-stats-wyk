---
title: "Introduction to Statistics"
subtitle: "Exercises: Part 1" 
author: Sophie Lee
format: 
  html:
    theme: 
      light: pulse
      dark: darkly
  pdf: 
    documentclass: scrreprt
---

```{r}
#| label: setup
#| include: false

pacman::p_load(tidyverse, flextable, kableExtra, ggforce, palmerpenguins, 
               car, Metrics)


```

## Exercise 1: Missing data

A mobile phone app collects user information. Some of this data are missing as users chose to opt out of location-based services. 

Give one scenario where the missing data would lead to **biased** analysis results. 

Give another scenario where the missing data leads to a reduced sample but could still be used to produce **unbiased** results.

## Exercise 2: Summary statistics

### Question 1
The following line graphs are taken from the Criminal Courts statistics quarterly report, showing the average number of days from offense to completion for defendants at the Crown Court. Which graph is the most appropriate to display the average time and why?

![Average number of days from offence to completion for defendants dealt with at the Crown Court, Q1 2014 â€“ Q4 2023](img/days_completion_cc.png)

### Question 2
The mean and standard deviation of waiting times in weeks for hearings in the Crown Court between 2020 and 2023 are given in the table below. Using this information, what can you tell about the distribution of these times?

```{r}
#| label: exercise2-table
#| echo: false


tibble(year = 2020:2023,
       mean_wait = c(13.5, 19.1, 20.9, 22.8),
       sd_wait = c(10.2, 15.6, 13.9, 14.7)) %>% 
  knitr::kable(col.names = c("Year", "Mean wait (weeks)", "SD wait (weeks)"))
```

## Exercise 3: Inferential statistics
The output below is taken from an analysis that compared reoffending behaviour of 249 men participating with the Keyworking programme from Only Connect (OC) with those receiving standard support. More information about the findings of this report and the intervention itself can be found on the [report webpage](https://www.gov.uk/government/statistics/justice-data-lab-statistics-january-2024/only-connect-report-html-version--2).

Comment on the way in which these results have been presented. Are the results clear? What has been done well? Is there anything you think could be improved? Do the results shown appear to be valid (from the information we are given)?

![](img/only_connect_table.png)

![](img/only_connect_figs.png)



## Exercise 4
Below are outputs from 4 models aiming to answer the research question: was body mass of penguins related to flipper length. 

Using model comparisons and checking the diagnostic tests, which model would you choose to use to answer this question and what would your answer be?

```{r}
#| label: models

lm_flipper <- lm(body_mass_g ~ flipper_length_mm, data = penguins)
lm_flipper_sex <- lm(body_mass_g ~ flipper_length_mm + sex, data = penguins)
lm_flipper_sex_bill <- lm(body_mass_g ~ flipper_length_mm + sex + bill_depth_mm, data = penguins)
lm_bill_sex<- lm(body_mass_g ~ sex + bill_depth_mm, data = penguins)

model_output <- function(model){
  broom::tidy(model, conf.int = T) %>% 
    mutate(across(is.numeric, ~round(., 2)),
           con.int = paste0("[", conf.low, ", ", conf.high, "]"),
           pvalue = ifelse(p.value == 0, "<0.01", p.value)) %>% 
    select(term, estimate, con.int, pvalue) %>% 
    kable(col.names = c("", "Coefficient", "95% CI", "p"))
}

models <- list(lm_flipper, lm_flipper_sex, lm_flipper_sex_bill, lm_bill_sex)

map(models, model_output)

evaluations <- function(model) {
  tibble(terms = attr(model$model, "term.labels"),
         adj.r = summary(model)$adj.r.squared,
         rmse = rmse(model$model$body_mass_g, predict(model)),
         mae = mae(model$model$body_mass_g, predict(model))) %>% 
    kable()
}
map(models, evaluations)

```


